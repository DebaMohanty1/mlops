import os
import json
import joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report
from imblearn.over_sampling import SMOTE

# ------------------------------------------------------------
# ğŸ“‚ Paths
DATA_PATH = "data/processed/train.csv"
MODEL_PATH = "models/model.pkl"
METRICS_PATH = "reports/metrics.json"
# ------------------------------------------------------------

# ------------------------------------------------------------
# ğŸ§© Load processed or merged data
# ------------------------------------------------------------
def load_data(path):
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ Processed data not found at {path}")
    df = pd.read_csv(path)
    print(f"âœ… Loaded processed data: {df.shape}")
    return df

# ------------------------------------------------------------
# âœ‚ï¸ Split into train/test
# ------------------------------------------------------------
def split_data(df):
    X = df.drop(columns=["Downtime"], errors="ignore")
    X = X.select_dtypes(include=["number"])
    y = df["Downtime"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    return X_train, X_test, y_train, y_test

# ------------------------------------------------------------
# âš–ï¸ Balance data using SMOTE
# ------------------------------------------------------------
def balance_data(X_train, y_train):
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X_train, y_train)
    print(f"âš–ï¸ After SMOTE: {dict(pd.Series(y_res).value_counts())}")
    return X_res, y_res

# ------------------------------------------------------------
# ğŸŒ² Train model
# ------------------------------------------------------------
def train_model(X_train, y_train):
    model = RandomForestClassifier(
        n_estimators=200, random_state=42, class_weight="balanced"
    )
    model.fit(X_train, y_train)
    return model

# ------------------------------------------------------------
# ğŸ“Š Evaluate model
# ------------------------------------------------------------
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    report = classification_report(
        y_test, y_pred, target_names=["NON_FAILURE", "FAILURE"]
    )
    print("\nğŸ“Š Classification Report:\n", report)
    return {"accuracy": acc, "f1_score": f1}

# ------------------------------------------------------------
# ğŸ’¾ Save model and metrics
# ------------------------------------------------------------
def save_artifacts(model, metrics):
    os.makedirs("models", exist_ok=True)
    os.makedirs("reports", exist_ok=True)

    joblib.dump(model, MODEL_PATH)
    print(f"ğŸ’¾ Model saved â†’ {MODEL_PATH}")

    with open(METRICS_PATH, "w") as f:
        json.dump(metrics, f, indent=4)
    print(f"ğŸ“ˆ Metrics saved â†’ {METRICS_PATH}")

# ------------------------------------------------------------
# ğŸª„ Promote dataset as new baseline
# ------------------------------------------------------------
def update_baseline(df, baseline_path="data/processed/train.csv", drift_score=None):
    os.makedirs(os.path.dirname(baseline_path), exist_ok=True)
    df.to_csv(baseline_path, index=False)
    print(f"ğŸ†• Baseline updated â†’ {baseline_path}")

    log_entry = {
        "timestamp": pd.Timestamp.now().isoformat(),
        "new_baseline_path": baseline_path,
        "rows": len(df),
        "columns": list(df.columns),
        "drift_score": drift_score,
    }

    drift_log_path = "reports/drift_log.json"
    os.makedirs(os.path.dirname(drift_log_path), exist_ok=True)
    if os.path.exists(drift_log_path):
        with open(drift_log_path, "r") as f:
            drift_log = json.load(f)
    else:
        drift_log = []

    drift_log.append(log_entry)
    with open(drift_log_path, "w") as f:
        json.dump(drift_log, f, indent=4)

    print(f"ğŸª„ Drift baseline promoted and logged â†’ {drift_log_path}")

# ------------------------------------------------------------
# ğŸ“¦ Load live drifted data
# ------------------------------------------------------------
def load_live_data(live_dir="data/live"):
    live_dfs = []
    if os.path.exists(live_dir):
        for f in os.listdir(live_dir):
            if f.startswith("current_") and f.endswith(".csv"):
                path = os.path.join(live_dir, f)
                try:
                    df_live = pd.read_csv(path)
                    live_dfs.append(df_live)
                    print(f"ğŸ“¦ Included drifted dataset: {f} ({df_live.shape})")
                except Exception as e:
                    print(f"âš ï¸ Skipping {f} â€” error: {e}")
    return live_dfs

# ------------------------------------------------------------
# ğŸš€ Main Training Logic (with NaN fix)
# ------------------------------------------------------------
def main():
    # 1ï¸âƒ£ Load baseline
    df = load_data(DATA_PATH)

    # 2ï¸âƒ£ Merge drifted datasets if present
    live_dfs = load_live_data()
    if live_dfs:
        print(f"ğŸ§  Loaded {len(live_dfs)} drifted datasets (for analysis only).")
    else:
        print("âœ… No drifted data to merge.")


    # 3ï¸âƒ£ Clean up and ensure numeric safety
    if "Downtime" in df.columns:
        df["Downtime"] = pd.to_numeric(df["Downtime"], errors="coerce")
        before = len(df)
        df = df.dropna(subset=["Downtime"])
        after = len(df)
        print(f"ğŸ§¹ Dropped {before - after} unlabeled rows (no Downtime).")
        df["Downtime"] = df["Downtime"].astype(int)
    else:
        raise ValueError("âŒ 'Downtime' target column missing after merge!")

    # 4ï¸âƒ£ Handle NaNs before SMOTE
    num_cols = df.select_dtypes(include=["number"]).columns
    df[num_cols] = df[num_cols].fillna(df[num_cols].median())

    if df[num_cols].isna().sum().any():
        print("âš ï¸ Warning: Some NaNs remain even after imputation.")
    else:
        print("âœ… No NaNs found after imputation.")

    # 5ï¸âƒ£ Split + train
    X_train, X_test, y_train, y_test = split_data(df)
    X_train_res, y_train_res = balance_data(X_train, y_train)
    model = train_model(X_train_res, y_train_res)

    # 6ï¸âƒ£ Evaluate and save
    metrics = evaluate_model(model, X_test, y_test)
    save_artifacts(model, metrics)

    # 7ï¸âƒ£ Update baseline reference
    try:
        update_baseline(df, drift_score=metrics.get("f1_score"))
    except Exception as e:
        print(f"âš ï¸ Baseline update failed: {e}")

    print("âœ… Training complete (drift-aware retraining done) and baseline refreshed!")

# ------------------------------------------------------------
if __name__ == "__main__":
    main()
